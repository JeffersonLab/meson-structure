{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Lambda CSV analysis example\n",
   "id": "efc9126d0f27e3f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "3a128a94345eafea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Working with multiple files as one Data Frame\n",
    "\n",
    "```bash\n",
    "# EDM4EIC with root-tree\n",
    "k_lambda_5x41_5000evt_001.edm4eic.root\n",
    "k_lambda_5x41_5000evt_002.edm4eic.root\n",
    "...\n",
    "\n",
    "# Corresponding CSV files:\n",
    "k_lambda_5x41_5000evt_001.mcdis.csv\n",
    "k_lambda_5x41_5000evt_001.mcpart_lambda.csv\n",
    "k_lambda_5x41_5000evt_002.mcdis.csv\n",
    "k_lambda_5x41_5000evt_002.mcpart_lambda.csv\n",
    "...\n",
    "```\n",
    "\n",
    "Each file such as `k_lambda_5x41_5000evt_001.edm4eic.root` is based on the processing 5000-events.\n",
    "It is convenient to have files split in small chunks like this, but\n",
    "analysis-wise 5k events are not statistically significant.\n",
    "So to get results, we want to combine several files in one dataframe.\n",
    "In general it is simple with pandas, but we have one problem.\n",
    "When we have multiple CSV files from different runs or datasets, each file starts its event numbering from 0:\n",
    "\n",
    "```\n",
    "File 1: evt = [0, 1, 2, 3, 4, ...]\n",
    "File 2: evt = [0, 1, 2, 3, 4, ...]  ← ID Collision!\n",
    "File 3: evt = [0, 1, 2, 3, 4, ...]  ← ID Collision!\n",
    "```\n",
    "\n",
    "**Problem**: Event 0 from File 1 is completely different from Event 0 from File 2, but they have the same ID!\n",
    "\n",
    "**Solution**: Global Unique Event IDs\n",
    "\n",
    "We need to create globally unique event IDs across all files that we open:\n"
   ],
   "id": "fa7d6ac0c254167f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T15:13:10.979662Z",
     "start_time": "2025-06-13T15:13:10.973370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def concat_csvs_with_unique_events(files):\n",
    "    \"\"\"Load and concatenate CSV files with globally unique event IDs\"\"\"\n",
    "    dfs = []\n",
    "    offset = 0\n",
    "\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        df['evt'] = df['evt'] + offset\n",
    "        offset = df['evt'].max() + 1\n",
    "        dfs.append(df)\n",
    "\n",
    "    return pd.concat(dfs, ignore_index=True)\n"
   ],
   "id": "76ad33d31cb873ff",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e9b612368fdcd209"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
